{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9560346,"sourceType":"datasetVersion","datasetId":5825923}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install impyute\n!pip install fancyimpute\nfrom sklearn import datasets\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom scipy import stats\nimport numpy as np\nimport impyute as impy\nfrom fancyimpute import IterativeSVD, SoftImpute, NuclearNormMinimization\nimport pandas as pd\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-06T13:56:32.675789Z","iopub.execute_input":"2024-10-06T13:56:32.676612Z","iopub.status.idle":"2024-10-06T13:56:56.900014Z","shell.execute_reply.started":"2024-10-06T13:56:32.676567Z","shell.execute_reply":"2024-10-06T13:56:56.898716Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Requirement already satisfied: impyute in /opt/conda/lib/python3.10/site-packages (0.0.8)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from impyute) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (3.5.0)\nRequirement already satisfied: fancyimpute in /opt/conda/lib/python3.10/site-packages (0.7.0)\nRequirement already satisfied: knnimpute>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (0.1.0)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.2.2)\nRequirement already satisfied: cvxpy in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.5.3)\nRequirement already satisfied: cvxopt in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.3.2)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (8.3.3)\nRequirement already satisfied: nose in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.3.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\nRequirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\nRequirement already satisfied: osqp>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.6.7.post1)\nRequirement already satisfied: ecos>=2 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (2.0.14)\nRequirement already satisfied: clarabel>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.9.0)\nRequirement already satisfied: scs>=3.2.4.post1 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (3.2.7)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (21.3)\nRequirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.1)\nRequirement already satisfied: qdldl in /opt/conda/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (0.1.7.post4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pytest->fancyimpute) (3.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef mle(Xtrain, n, p, G):\n    '''\n    Xtrain: List of input. The ith element of the list contains samples from the ith class.\n    Adjusted for the health-related dataset.\n    '''\n    if p[0] == 1:\n        mus = [np.mean(Xtrain[g][:, 0]) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.var(Xtrain[g][:, 0]) for g in np.arange(G)]\n    else:\n        mus = [np.mean(Xtrain[g][:, 0:p[0]], axis=0) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.cov(Xtrain[g][:, 0:p[0]], rowvar=False) for g in np.arange(G)]\n\n    mus = np.asarray(mus).T\n    S = sum(S) / (sum(n[:, 0]))\n    S = S.reshape((p[0], -1))\n\n    for i in np.arange(1, len(p)):\n        W = [(n[g, i] - 1) * np.cov(Xtrain[g][0:n[g, i], 0:p[i]], rowvar=False) for g in np.arange(G)]\n        W = sum(W)\n\n        P = np.matmul(W[(p[i - 1]):p[i], 0:p[i - 1]], np.linalg.inv(W[0:p[i - 1], 0:p[i - 1]]))\n        Q = (W[p[i - 1]:p[i], p[i - 1]:p[i]] - np.matmul(P, W[0:p[i - 1], p[i - 1]:p[i]])) / sum(n[:, i])\n\n        xmeans = [np.mean(Xtrain[g][0:n[g, i], 0:p[i]], axis=0) for g in np.arange(G)]\n        xmeans = np.asarray(xmeans).T\n\n        mus = np.vstack((mus, xmeans[p[i - 1]:p[i], :] - np.matmul(P, xmeans[0:p[i - 1]] - mus)))\n        S21 = np.matmul(P, S)\n        S = np.vstack((np.hstack((S, S21.T)), np.hstack((S21, Q + np.matmul(P, S21.T)))))\n\n    return [mus, S]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:56:56.902561Z","iopub.execute_input":"2024-10-06T13:56:56.902932Z","iopub.status.idle":"2024-10-06T13:56:56.919945Z","shell.execute_reply.started":"2024-10-06T13:56:56.902893Z","shell.execute_reply":"2024-10-06T13:56:56.918894Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Function to calculate misclassification rate for LDA with missing data\ndef lda_miss(mus, S, Xtest, ytrain, ytest, G):\n    f = lambda g: np.log(np.mean(ytrain == g)) - np.matmul(\n                  np.matmul(mus[:,g].T, np.linalg.inv(S)), mus[:,g]/2)\n    last2 = [f(g) for g in np.arange(G)]\n\n    h = lambda g, i: last2[g] + np.matmul(mus[:, g].T, np.matmul(\n                    np.linalg.inv(S), Xtest[i, :].T))\n\n    pred_label = [np.argmax([h(g, i) for g in np.arange(G)])\n                  for i in np.arange(len(Xtest))]\n\n    pred_label = np.asarray(pred_label)\n    return np.mean(pred_label.flatten() != ytest)\n\n# Function to create data list with missing values\ndef make_nan_list(X, y, G, n, p):\n    # Labels should range from 0 to G-1\n    data = []\n    for g in np.arange(G):\n        data.append(X[y == g, :])\n        for k in np.arange(len(p) - 1):\n            data[g][n[g, k + 1]:n[g, k], p[k]:] = np.nan\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:56:56.921417Z","iopub.execute_input":"2024-10-06T13:56:56.921763Z","iopub.status.idle":"2024-10-06T13:56:56.935501Z","shell.execute_reply.started":"2024-10-06T13:56:56.921731Z","shell.execute_reply":"2024-10-06T13:56:56.934653Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def missing_rate(Xtrain, ytrain, n, p, G):\n    Xtr_nan_list = make_nan_list(Xtrain, ytrain, G, n, p)\n    # Generate missing data and a new ytrain since the order might change\n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n\n    for g in np.arange(1, G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # Calculate the percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n    return per_missing","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:56:56.937698Z","iopub.execute_input":"2024-10-06T13:56:56.937981Z","iopub.status.idle":"2024-10-06T13:56:56.951716Z","shell.execute_reply.started":"2024-10-06T13:56:56.937950Z","shell.execute_reply":"2024-10-06T13:56:56.950863Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def compute_err_kNN(Xtrain, ytrain, Xtest, ytest, n, p, G):    \n    Xtr_nan_list = make_nan_list(Xtrain,ytrain,G, n, p)\n    # make NA data\n    # since making function changes the order of observation\n    # we need to generate new ytr from Xtr_nan    \n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n    for g in np.arange(1,G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n\n    scaler = MinMaxScaler()\n    scaler.fit(Xtr_nan)\n    Xtr_nan = scaler.transform(Xtr_nan)\n    Xtest = scaler.transform(Xtest)\n    Xtr_nan_list2 = []\n    for g in range(G):\n      Xtr_nan_list2.append(scaler.transform(Xtr_nan_list[g]))\n\n    start = time.time()\n    Xtr_knn = impy.fast_knn(Xtr_nan, k=1)\n    print(\"Finished imputing\")\n    clf_knn = skLDA().fit(Xtr_knn, ytr)\n    knn_err = np.mean(clf_knn.predict(Xtest).flatten() != ytest)\n    knn_time = time.time()-start \n\n    return knn_err, knn_time","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:56:56.952866Z","iopub.execute_input":"2024-10-06T13:56:56.953674Z","iopub.status.idle":"2024-10-06T13:56:56.963070Z","shell.execute_reply.started":"2024-10-06T13:56:56.953634Z","shell.execute_reply":"2024-10-06T13:56:56.962293Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset instead of MNIST\ndata = pd.read_csv('/kaggle/input/large-diab/large_diab.csv')\n\n# Split into train and test sets if not already done\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Extract features and target\nXtrain = train_data.drop('HeartDiseaseorAttack', axis=1)  # Assuming 'diabetes_status' is the target\nytrain = train_data['HeartDiseaseorAttack']\nXtest = test_data.drop('HeartDiseaseorAttack', axis=1)\nytest = test_data['HeartDiseaseorAttack']","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:56:56.964171Z","iopub.execute_input":"2024-10-06T13:56:56.964477Z","iopub.status.idle":"2024-10-06T13:56:57.628976Z","shell.execute_reply.started":"2024-10-06T13:56:56.964445Z","shell.execute_reply":"2024-10-06T13:56:57.628130Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"data.info","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:56:57.630251Z","iopub.execute_input":"2024-10-06T13:56:57.630643Z","iopub.status.idle":"2024-10-06T13:56:57.667938Z","shell.execute_reply.started":"2024-10-06T13:56:57.630601Z","shell.execute_reply":"2024-10-06T13:56:57.667077Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of         HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n0                        0.0     1.0       1.0        1.0  40.0     1.0   \n1                        0.0     0.0       0.0        0.0  25.0     1.0   \n2                        0.0     1.0       1.0        1.0  28.0     0.0   \n3                        0.0     1.0       0.0        1.0  27.0     0.0   \n4                        0.0     1.0       1.0        1.0  24.0     0.0   \n...                      ...     ...       ...        ...   ...     ...   \n253675                   0.0     1.0       1.0        1.0  45.0     0.0   \n253676                   0.0     1.0       1.0        1.0  18.0     0.0   \n253677                   0.0     0.0       0.0        1.0  28.0     0.0   \n253678                   0.0     1.0       0.0        1.0  23.0     0.0   \n253679                   1.0     1.0       1.0        1.0  25.0     0.0   \n\n        Stroke  Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  \\\n0          0.0       0.0           0.0     0.0  ...            1.0   \n1          0.0       0.0           1.0     0.0  ...            0.0   \n2          0.0       0.0           0.0     1.0  ...            1.0   \n3          0.0       0.0           1.0     1.0  ...            1.0   \n4          0.0       0.0           1.0     1.0  ...            1.0   \n...        ...       ...           ...     ...  ...            ...   \n253675     0.0       0.0           0.0     1.0  ...            1.0   \n253676     0.0       2.0           0.0     0.0  ...            1.0   \n253677     0.0       0.0           1.0     1.0  ...            1.0   \n253678     0.0       0.0           0.0     1.0  ...            1.0   \n253679     0.0       2.0           1.0     1.0  ...            1.0   \n\n        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n...             ...      ...       ...       ...       ...  ...   ...   \n253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n\n        Education  Income  \n0             4.0     3.0  \n1             6.0     1.0  \n2             4.0     8.0  \n3             3.0     6.0  \n4             5.0     4.0  \n...           ...     ...  \n253675        6.0     7.0  \n253676        2.0     4.0  \n253677        5.0     2.0  \n253678        5.0     1.0  \n253679        6.0     2.0  \n\n[253680 rows x 22 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the dataset to NumPy arrays\nXtrain_np, ytrain_np = [], []\nfor index, row in train_data.iterrows():\n    Xtrain_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytrain_np.append(row['HeartDiseaseorAttack'])\n\nXtrain, ytrain = np.asarray(Xtrain_np), np.asarray(ytrain_np)\n\n# Set random seed and shuffle the data\nnp.random.seed(1)\nidx = np.arange(len(ytrain))\nnp.random.shuffle(idx)\nXtrain, ytrain = Xtrain[idx, :], ytrain[idx]\n\nXtrain.shape, ytrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:56:57.669003Z","iopub.execute_input":"2024-10-06T13:56:57.669312Z","iopub.status.idle":"2024-10-06T13:57:59.423134Z","shell.execute_reply.started":"2024-10-06T13:56:57.669280Z","shell.execute_reply":"2024-10-06T13:57:59.421992Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (202944,))"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the test set to NumPy arrays\nXtest_np, ytest_np = [], []\nfor index, row in test_data.iterrows():\n    Xtest_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytest_np.append(row['HeartDiseaseorAttack'])\n\nXtest, ytest = np.asarray(Xtest_np), np.asarray(ytest_np)\n\nXtest = Xtest.astype(float)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:57:59.424771Z","iopub.execute_input":"2024-10-06T13:57:59.425097Z","iopub.status.idle":"2024-10-06T13:58:15.070514Z","shell.execute_reply.started":"2024-10-06T13:57:59.425062Z","shell.execute_reply":"2024-10-06T13:58:15.069637Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Check if a column is mostly zeros (all or almost all zeroes)\nid = [np.sum(Xtrain[:, i] != 0) > 10 for i in range(Xtrain.shape[1])]\n\n# Number of columns that are mostly zero\nprint(Xtrain.shape[1] - np.sum(id))\n\n# Number of columns with more than 10 non-zero values\nprint(np.sum(id))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:58:15.074456Z","iopub.execute_input":"2024-10-06T13:58:15.074771Z","iopub.status.idle":"2024-10-06T13:58:15.106658Z","shell.execute_reply.started":"2024-10-06T13:58:15.074739Z","shell.execute_reply":"2024-10-06T13:58:15.105630Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"0\n21\n","output_type":"stream"}]},{"cell_type":"code","source":"Xtrain, Xtest = Xtrain[:,id], Xtest[:,id]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:58:15.107940Z","iopub.execute_input":"2024-10-06T13:58:15.108329Z","iopub.status.idle":"2024-10-06T13:58:15.137797Z","shell.execute_reply.started":"2024-10-06T13:58:15.108293Z","shell.execute_reply":"2024-10-06T13:58:15.136942Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"Xtrain.shape, Xtest.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:58:15.138929Z","iopub.execute_input":"2024-10-06T13:58:15.139274Z","iopub.status.idle":"2024-10-06T13:58:15.145493Z","shell.execute_reply.started":"2024-10-06T13:58:15.139239Z","shell.execute_reply":"2024-10-06T13:58:15.144521Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (50736, 21))"},"metadata":{}}]},{"cell_type":"code","source":"# Number of samples per class in training data (assuming classes 0 and 1 for diabetes classification)\nng = np.asarray([sum(ytrain == i) for i in np.unique(ytrain)])\nng","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:58:15.147141Z","iopub.execute_input":"2024-10-06T13:58:15.147618Z","iopub.status.idle":"2024-10-06T13:58:15.253833Z","shell.execute_reply.started":"2024-10-06T13:58:15.147574Z","shell.execute_reply":"2024-10-06T13:58:15.252816Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"array([183819,  19125])"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 20% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([200000, 180000, 160000, 140000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:58:15.254947Z","iopub.execute_input":"2024-10-06T13:58:15.255297Z","iopub.status.idle":"2024-10-06T13:58:15.321168Z","shell.execute_reply.started":"2024-10-06T13:58:15.255264Z","shell.execute_reply":"2024-10-06T13:58:15.320183Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.05030029395864306"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_kNN(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:58:15.322549Z","iopub.execute_input":"2024-10-06T13:58:15.322969Z","iopub.status.idle":"2024-10-06T13:58:16.045874Z","shell.execute_reply.started":"2024-10-06T13:58:15.322921Z","shell.execute_reply":"2024-10-06T13:58:16.044421Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_err_kNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[26], line 23\u001b[0m, in \u001b[0;36mcompute_err_kNN\u001b[0;34m(Xtrain, ytrain, Xtest, ytest, n, p, G)\u001b[0m\n\u001b[1;32m     20\u001b[0m   Xtr_nan_list2\u001b[38;5;241m.\u001b[39mappend(scaler\u001b[38;5;241m.\u001b[39mtransform(Xtr_nan_list[g]))\n\u001b[1;32m     22\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 23\u001b[0m Xtr_knn \u001b[38;5;241m=\u001b[39m \u001b[43mimpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_knn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished imputing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m clf_knn \u001b[38;5;241m=\u001b[39m skLDA()\u001b[38;5;241m.\u001b[39mfit(Xtr_knn, ytr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/impyute/util/preprocess.py:55\u001b[0m, in \u001b[0;36mpreprocess.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd_DataFrame(fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/impyute/util/checks.py:32\u001b[0m, in \u001b[0;36mchecks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_ndarray(data):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadInputError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot a np.ndarray.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_dtype_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadInputError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData is not float.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _nan_exists(data):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/impyute/util/checks.py:53\u001b[0m, in \u001b[0;36m_dtype_float\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dtype_float\u001b[39m(data):\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" True if the values in the array are floating point\"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n","\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"],"ename":"AttributeError","evalue":"module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations","output_type":"error"}]}]}