{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9560346,"sourceType":"datasetVersion","datasetId":5825923}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install impyute\n!pip install fancyimpute\nfrom sklearn import datasets\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom scipy import stats\nimport numpy as np\nimport impyute as impy\nfrom fancyimpute import IterativeSVD, SoftImpute, NuclearNormMinimization\nimport pandas as pd\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-06T13:10:24.426953Z","iopub.execute_input":"2024-10-06T13:10:24.427559Z","iopub.status.idle":"2024-10-06T13:10:58.928725Z","shell.execute_reply.started":"2024-10-06T13:10:24.427522Z","shell.execute_reply":"2024-10-06T13:10:58.927904Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting impyute\n  Downloading impyute-0.0.8-py2.py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from impyute) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (3.5.0)\nDownloading impyute-0.0.8-py2.py3-none-any.whl (31 kB)\nInstalling collected packages: impyute\nSuccessfully installed impyute-0.0.8\nCollecting fancyimpute\n  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting knnimpute>=0.1.0 (from fancyimpute)\n  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.2.2)\nCollecting cvxpy (from fancyimpute)\n  Downloading cvxpy-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\nCollecting cvxopt (from fancyimpute)\n  Downloading cvxopt-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (8.3.3)\nRequirement already satisfied: nose in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.3.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\nRequirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\nCollecting osqp>=0.6.2 (from cvxpy->fancyimpute)\n  Downloading osqp-0.6.7.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\nRequirement already satisfied: ecos>=2 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (2.0.14)\nCollecting clarabel>=0.5.0 (from cvxpy->fancyimpute)\n  Downloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nCollecting scs>=3.2.4.post1 (from cvxpy->fancyimpute)\n  Downloading scs-3.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (21.3)\nRequirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.1)\nCollecting qdldl (from osqp>=0.6.2->cvxpy->fancyimpute)\n  Downloading qdldl-0.1.7.post4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pytest->fancyimpute) (3.1.2)\nDownloading cvxopt-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading cvxpy-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading osqp-0.6.7.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scs-3.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading qdldl-0.1.7.post4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fancyimpute, knnimpute\n  Building wheel for fancyimpute (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29881 sha256=edb62b55996d2a6864a9f873e8c58a5e36efda9d8fdaab4968939ac14d4521db\n  Stored in directory: /root/.cache/pip/wheels/7b/0c/d3/ee82d1fbdcc0858d96434af108608d01703505d453720c84ed\n  Building wheel for knnimpute (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11330 sha256=aae6e6122ec77b1ae8d2d52b275ed4f8e6905caa89f803c4eb7dedf0395c0bf8\n  Stored in directory: /root/.cache/pip/wheels/46/06/a5/45a724630562413c374e29c08732411d496092408b3a7bf754\nSuccessfully built fancyimpute knnimpute\nInstalling collected packages: knnimpute, cvxopt, scs, qdldl, clarabel, osqp, cvxpy, fancyimpute\nSuccessfully installed clarabel-0.9.0 cvxopt-1.3.2 cvxpy-1.5.3 fancyimpute-0.7.0 knnimpute-0.1.0 osqp-0.6.7.post1 qdldl-0.1.7.post4 scs-3.2.7\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef mle(Xtrain, n, p, G):\n    '''\n    Xtrain: List of input. The ith element of the list contains samples from the ith class.\n    Adjusted for the health-related dataset.\n    '''\n    if p[0] == 1:\n        mus = [np.mean(Xtrain[g][:, 0]) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.var(Xtrain[g][:, 0]) for g in np.arange(G)]\n    else:\n        mus = [np.mean(Xtrain[g][:, 0:p[0]], axis=0) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.cov(Xtrain[g][:, 0:p[0]], rowvar=False) for g in np.arange(G)]\n\n    mus = np.asarray(mus).T\n    S = sum(S) / (sum(n[:, 0]))\n    S = S.reshape((p[0], -1))\n\n    for i in np.arange(1, len(p)):\n        W = [(n[g, i] - 1) * np.cov(Xtrain[g][0:n[g, i], 0:p[i]], rowvar=False) for g in np.arange(G)]\n        W = sum(W)\n\n        P = np.matmul(W[(p[i - 1]):p[i], 0:p[i - 1]], np.linalg.inv(W[0:p[i - 1], 0:p[i - 1]]))\n        Q = (W[p[i - 1]:p[i], p[i - 1]:p[i]] - np.matmul(P, W[0:p[i - 1], p[i - 1]:p[i]])) / sum(n[:, i])\n\n        xmeans = [np.mean(Xtrain[g][0:n[g, i], 0:p[i]], axis=0) for g in np.arange(G)]\n        xmeans = np.asarray(xmeans).T\n\n        mus = np.vstack((mus, xmeans[p[i - 1]:p[i], :] - np.matmul(P, xmeans[0:p[i - 1]] - mus)))\n        S21 = np.matmul(P, S)\n        S = np.vstack((np.hstack((S, S21.T)), np.hstack((S21, Q + np.matmul(P, S21.T)))))\n\n    return [mus, S]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:14:11.459246Z","iopub.execute_input":"2024-10-06T13:14:11.460278Z","iopub.status.idle":"2024-10-06T13:14:11.475413Z","shell.execute_reply.started":"2024-10-06T13:14:11.460238Z","shell.execute_reply":"2024-10-06T13:14:11.474506Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Function to calculate misclassification rate for LDA with missing data\ndef lda_miss(mus, S, Xtest, ytrain, ytest, G):\n    f = lambda g: np.log(np.mean(ytrain == g)) - np.matmul(\n                  np.matmul(mus[:,g].T, np.linalg.inv(S)), mus[:,g]/2)\n    last2 = [f(g) for g in np.arange(G)]\n\n    h = lambda g, i: last2[g] + np.matmul(mus[:, g].T, np.matmul(\n                    np.linalg.inv(S), Xtest[i, :].T))\n\n    pred_label = [np.argmax([h(g, i) for g in np.arange(G)])\n                  for i in np.arange(len(Xtest))]\n\n    pred_label = np.asarray(pred_label)\n    return np.mean(pred_label.flatten() != ytest)\n\n# Function to create data list with missing values\ndef make_nan_list(X, y, G, n, p):\n    # Labels should range from 0 to G-1\n    data = []\n    for g in np.arange(G):\n        data.append(X[y == g, :])\n        for k in np.arange(len(p) - 1):\n            data[g][n[g, k + 1]:n[g, k], p[k]:] = np.nan\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:14:22.214908Z","iopub.execute_input":"2024-10-06T13:14:22.215579Z","iopub.status.idle":"2024-10-06T13:14:22.225477Z","shell.execute_reply.started":"2024-10-06T13:14:22.215538Z","shell.execute_reply":"2024-10-06T13:14:22.224389Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def missing_rate(Xtrain, ytrain, n, p, G):\n    Xtr_nan_list = make_nan_list(Xtrain, ytrain, G, n, p)\n    # Generate missing data and a new ytrain since the order might change\n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n\n    for g in np.arange(1, G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # Calculate the percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n    return per_missing","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:14:33.622238Z","iopub.execute_input":"2024-10-06T13:14:33.622640Z","iopub.status.idle":"2024-10-06T13:14:33.629501Z","shell.execute_reply.started":"2024-10-06T13:14:33.622601Z","shell.execute_reply":"2024-10-06T13:14:33.628498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def compute_err_MLE(Xtrain, ytrain, Xtest, ytest, n, p, G):    \n    Xtr_nan_list = make_nan_list(Xtrain,ytrain,G, n, p)\n    # make NA data\n    # since making function changes the order of observation\n    # we need to generate new ytr from Xtr_nan    \n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n    for g in np.arange(1,G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n\n    scaler = MinMaxScaler()\n    scaler.fit(Xtr_nan)\n    Xtr_nan = scaler.transform(Xtr_nan)\n    Xtest = scaler.transform(Xtest)\n    Xtr_nan_list2 = []\n    for g in range(G):\n      Xtr_nan_list2.append(scaler.transform(Xtr_nan_list[g]))\n\n    # MLEs approach\n    start = time.time()\n    mus, S = mle(Xtr_nan_list2, n, p, G)\n    mle_err = lda_miss(mus, S, Xtest, ytrain, ytest, G)\n    mle_time = time.time()-start\n  \n    return mle_err, mle_time","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:14:42.500070Z","iopub.execute_input":"2024-10-06T13:14:42.500498Z","iopub.status.idle":"2024-10-06T13:14:42.510013Z","shell.execute_reply.started":"2024-10-06T13:14:42.500461Z","shell.execute_reply":"2024-10-06T13:14:42.509043Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset instead of MNIST\ndata = pd.read_csv('/kaggle/input/large-diab/large_diab.csv')\n\n# Split into train and test sets if not already done\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Extract features and target\nXtrain = train_data.drop('HeartDiseaseorAttack', axis=1)  # Assuming 'diabetes_status' is the target\nytrain = train_data['HeartDiseaseorAttack']\nXtest = test_data.drop('HeartDiseaseorAttack', axis=1)\nytest = test_data['HeartDiseaseorAttack']","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:18:41.548706Z","iopub.execute_input":"2024-10-06T13:18:41.549362Z","iopub.status.idle":"2024-10-06T13:18:42.743663Z","shell.execute_reply.started":"2024-10-06T13:18:41.549323Z","shell.execute_reply":"2024-10-06T13:18:42.742790Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data.info","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:18:57.094908Z","iopub.execute_input":"2024-10-06T13:18:57.095793Z","iopub.status.idle":"2024-10-06T13:18:57.140039Z","shell.execute_reply.started":"2024-10-06T13:18:57.095749Z","shell.execute_reply":"2024-10-06T13:18:57.139044Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of         HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n0                        0.0     1.0       1.0        1.0  40.0     1.0   \n1                        0.0     0.0       0.0        0.0  25.0     1.0   \n2                        0.0     1.0       1.0        1.0  28.0     0.0   \n3                        0.0     1.0       0.0        1.0  27.0     0.0   \n4                        0.0     1.0       1.0        1.0  24.0     0.0   \n...                      ...     ...       ...        ...   ...     ...   \n253675                   0.0     1.0       1.0        1.0  45.0     0.0   \n253676                   0.0     1.0       1.0        1.0  18.0     0.0   \n253677                   0.0     0.0       0.0        1.0  28.0     0.0   \n253678                   0.0     1.0       0.0        1.0  23.0     0.0   \n253679                   1.0     1.0       1.0        1.0  25.0     0.0   \n\n        Stroke  Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  \\\n0          0.0       0.0           0.0     0.0  ...            1.0   \n1          0.0       0.0           1.0     0.0  ...            0.0   \n2          0.0       0.0           0.0     1.0  ...            1.0   \n3          0.0       0.0           1.0     1.0  ...            1.0   \n4          0.0       0.0           1.0     1.0  ...            1.0   \n...        ...       ...           ...     ...  ...            ...   \n253675     0.0       0.0           0.0     1.0  ...            1.0   \n253676     0.0       2.0           0.0     0.0  ...            1.0   \n253677     0.0       0.0           1.0     1.0  ...            1.0   \n253678     0.0       0.0           0.0     1.0  ...            1.0   \n253679     0.0       2.0           1.0     1.0  ...            1.0   \n\n        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n...             ...      ...       ...       ...       ...  ...   ...   \n253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n\n        Education  Income  \n0             4.0     3.0  \n1             6.0     1.0  \n2             4.0     8.0  \n3             3.0     6.0  \n4             5.0     4.0  \n...           ...     ...  \n253675        6.0     7.0  \n253676        2.0     4.0  \n253677        5.0     2.0  \n253678        5.0     1.0  \n253679        6.0     2.0  \n\n[253680 rows x 22 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the dataset to NumPy arrays\nXtrain_np, ytrain_np = [], []\nfor index, row in train_data.iterrows():\n    Xtrain_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytrain_np.append(row['HeartDiseaseorAttack'])\n\nXtrain, ytrain = np.asarray(Xtrain_np), np.asarray(ytrain_np)\n\n# Set random seed and shuffle the data\nnp.random.seed(1)\nidx = np.arange(len(ytrain))\nnp.random.shuffle(idx)\nXtrain, ytrain = Xtrain[idx, :], ytrain[idx]\n\nXtrain.shape, ytrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:19:16.806241Z","iopub.execute_input":"2024-10-06T13:19:16.806609Z","iopub.status.idle":"2024-10-06T13:20:15.482073Z","shell.execute_reply.started":"2024-10-06T13:19:16.806576Z","shell.execute_reply":"2024-10-06T13:20:15.481068Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (202944,))"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the test set to NumPy arrays\nXtest_np, ytest_np = [], []\nfor index, row in test_data.iterrows():\n    Xtest_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytest_np.append(row['HeartDiseaseorAttack'])\n\nXtest, ytest = np.asarray(Xtest_np), np.asarray(ytest_np)\n\nXtest = Xtest.astype(float)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:15.483828Z","iopub.execute_input":"2024-10-06T13:20:15.484192Z","iopub.status.idle":"2024-10-06T13:20:30.979649Z","shell.execute_reply.started":"2024-10-06T13:20:15.484156Z","shell.execute_reply":"2024-10-06T13:20:30.978891Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Check if a column is mostly zeros (all or almost all zeroes)\nid = [np.sum(Xtrain[:, i] != 0) > 10 for i in range(Xtrain.shape[1])]\n\n# Number of columns that are mostly zero\nprint(Xtrain.shape[1] - np.sum(id))\n\n# Number of columns with more than 10 non-zero values\nprint(np.sum(id))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:30.980705Z","iopub.execute_input":"2024-10-06T13:20:30.980993Z","iopub.status.idle":"2024-10-06T13:20:31.014950Z","shell.execute_reply.started":"2024-10-06T13:20:30.980962Z","shell.execute_reply":"2024-10-06T13:20:31.014057Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"0\n21\n","output_type":"stream"}]},{"cell_type":"code","source":"Xtrain, Xtest = Xtrain[:,id], Xtest[:,id]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:31.016976Z","iopub.execute_input":"2024-10-06T13:20:31.017285Z","iopub.status.idle":"2024-10-06T13:20:31.051128Z","shell.execute_reply.started":"2024-10-06T13:20:31.017253Z","shell.execute_reply":"2024-10-06T13:20:31.050348Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"Xtrain.shape, Xtest.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:31.052204Z","iopub.execute_input":"2024-10-06T13:20:31.052485Z","iopub.status.idle":"2024-10-06T13:20:31.058436Z","shell.execute_reply.started":"2024-10-06T13:20:31.052456Z","shell.execute_reply":"2024-10-06T13:20:31.057646Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (50736, 21))"},"metadata":{}}]},{"cell_type":"code","source":"# Number of samples per class in training data (assuming classes 0 and 1 for diabetes classification)\nng = np.asarray([sum(ytrain == i) for i in np.unique(ytrain)])\nng","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:31.059435Z","iopub.execute_input":"2024-10-06T13:20:31.059724Z","iopub.status.idle":"2024-10-06T13:20:31.162912Z","shell.execute_reply.started":"2024-10-06T13:20:31.059684Z","shell.execute_reply":"2024-10-06T13:20:31.162134Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([183819,  19125])"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 20% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([200000, 180000, 160000, 140000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:31.521884Z","iopub.execute_input":"2024-10-06T13:20:31.522184Z","iopub.status.idle":"2024-10-06T13:20:31.585252Z","shell.execute_reply.started":"2024-10-06T13:20:31.522150Z","shell.execute_reply":"2024-10-06T13:20:31.584382Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0.05030029395864306"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MLE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:42.684362Z","iopub.execute_input":"2024-10-06T13:20:42.684997Z","iopub.status.idle":"2024-10-06T13:20:54.775612Z","shell.execute_reply.started":"2024-10-06T13:20:42.684958Z","shell.execute_reply":"2024-10-06T13:20:54.774333Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(0.09803689687795648, 11.92579174041748)"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 30% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([140000, 120000, 110000, 90000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value_30 = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value_30","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:54.782264Z","iopub.execute_input":"2024-10-06T13:20:54.785740Z","iopub.status.idle":"2024-10-06T13:20:54.904419Z","shell.execute_reply.started":"2024-10-06T13:20:54.785674Z","shell.execute_reply":"2024-10-06T13:20:54.903606Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0.18349162236638586"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MLE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:20:58.918468Z","iopub.execute_input":"2024-10-06T13:20:58.918861Z","iopub.status.idle":"2024-10-06T13:21:12.072946Z","shell.execute_reply.started":"2024-10-06T13:20:58.918824Z","shell.execute_reply":"2024-10-06T13:21:12.071550Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(0.09809602649006623, 12.982503890991211)"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 40% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([120000, 100000, 80000, 60000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value_40 = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value_40","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:23:04.403932Z","iopub.execute_input":"2024-10-06T13:23:04.404870Z","iopub.status.idle":"2024-10-06T13:23:04.476622Z","shell.execute_reply.started":"2024-10-06T13:23:04.404827Z","shell.execute_reply":"2024-10-06T13:23:04.475631Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.24919119137721313"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MLE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:23:12.404208Z","iopub.execute_input":"2024-10-06T13:23:12.404944Z","iopub.status.idle":"2024-10-06T13:23:24.241944Z","shell.execute_reply.started":"2024-10-06T13:23:12.404906Z","shell.execute_reply":"2024-10-06T13:23:24.240634Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(0.09797776726584674, 11.686202764511108)"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 50% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([100000, 90000, 80000, 70000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value_50 = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value_50","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:23:24.244690Z","iopub.execute_input":"2024-10-06T13:23:24.245211Z","iopub.status.idle":"2024-10-06T13:23:24.368080Z","shell.execute_reply.started":"2024-10-06T13:23:24.245152Z","shell.execute_reply":"2024-10-06T13:23:24.367366Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.2585768440930456"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MLE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:23:28.660456Z","iopub.execute_input":"2024-10-06T13:23:28.661063Z","iopub.status.idle":"2024-10-06T13:23:42.225951Z","shell.execute_reply.started":"2024-10-06T13:23:28.661023Z","shell.execute_reply":"2024-10-06T13:23:42.224532Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(0.09801718700725323, 13.409820318222046)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}