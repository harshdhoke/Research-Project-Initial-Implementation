{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9560346,"sourceType":"datasetVersion","datasetId":5825923}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install impyute\n!pip install fancyimpute\nfrom sklearn import datasets\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom scipy import stats\nimport numpy as np\nimport impyute as impy\nfrom fancyimpute import IterativeSVD, SoftImpute, NuclearNormMinimization\nimport pandas as pd\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-06T13:27:18.681994Z","iopub.execute_input":"2024-10-06T13:27:18.682389Z","iopub.status.idle":"2024-10-06T13:27:41.886726Z","shell.execute_reply.started":"2024-10-06T13:27:18.682353Z","shell.execute_reply":"2024-10-06T13:27:41.885183Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: impyute in /opt/conda/lib/python3.10/site-packages (0.0.8)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from impyute) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (3.5.0)\nRequirement already satisfied: fancyimpute in /opt/conda/lib/python3.10/site-packages (0.7.0)\nRequirement already satisfied: knnimpute>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (0.1.0)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.2.2)\nRequirement already satisfied: cvxpy in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.5.3)\nRequirement already satisfied: cvxopt in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.3.2)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (8.3.3)\nRequirement already satisfied: nose in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.3.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\nRequirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\nRequirement already satisfied: osqp>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.6.7.post1)\nRequirement already satisfied: ecos>=2 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (2.0.14)\nRequirement already satisfied: clarabel>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.9.0)\nRequirement already satisfied: scs>=3.2.4.post1 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (3.2.7)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (21.3)\nRequirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.1)\nRequirement already satisfied: qdldl in /opt/conda/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (0.1.7.post4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pytest->fancyimpute) (3.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef mle(Xtrain, n, p, G):\n    '''\n    Xtrain: List of input. The ith element of the list contains samples from the ith class.\n    Adjusted for the health-related dataset.\n    '''\n    if p[0] == 1:\n        mus = [np.mean(Xtrain[g][:, 0]) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.var(Xtrain[g][:, 0]) for g in np.arange(G)]\n    else:\n        mus = [np.mean(Xtrain[g][:, 0:p[0]], axis=0) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.cov(Xtrain[g][:, 0:p[0]], rowvar=False) for g in np.arange(G)]\n\n    mus = np.asarray(mus).T\n    S = sum(S) / (sum(n[:, 0]))\n    S = S.reshape((p[0], -1))\n\n    for i in np.arange(1, len(p)):\n        W = [(n[g, i] - 1) * np.cov(Xtrain[g][0:n[g, i], 0:p[i]], rowvar=False) for g in np.arange(G)]\n        W = sum(W)\n\n        P = np.matmul(W[(p[i - 1]):p[i], 0:p[i - 1]], np.linalg.inv(W[0:p[i - 1], 0:p[i - 1]]))\n        Q = (W[p[i - 1]:p[i], p[i - 1]:p[i]] - np.matmul(P, W[0:p[i - 1], p[i - 1]:p[i]])) / sum(n[:, i])\n\n        xmeans = [np.mean(Xtrain[g][0:n[g, i], 0:p[i]], axis=0) for g in np.arange(G)]\n        xmeans = np.asarray(xmeans).T\n\n        mus = np.vstack((mus, xmeans[p[i - 1]:p[i], :] - np.matmul(P, xmeans[0:p[i - 1]] - mus)))\n        S21 = np.matmul(P, S)\n        S = np.vstack((np.hstack((S, S21.T)), np.hstack((S21, Q + np.matmul(P, S21.T)))))\n\n    return [mus, S]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:27:41.889762Z","iopub.execute_input":"2024-10-06T13:27:41.890855Z","iopub.status.idle":"2024-10-06T13:27:41.922031Z","shell.execute_reply.started":"2024-10-06T13:27:41.890797Z","shell.execute_reply":"2024-10-06T13:27:41.920346Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Function to calculate misclassification rate for LDA with missing data\ndef lda_miss(mus, S, Xtest, ytrain, ytest, G):\n    f = lambda g: np.log(np.mean(ytrain == g)) - np.matmul(\n                  np.matmul(mus[:,g].T, np.linalg.inv(S)), mus[:,g]/2)\n    last2 = [f(g) for g in np.arange(G)]\n\n    h = lambda g, i: last2[g] + np.matmul(mus[:, g].T, np.matmul(\n                    np.linalg.inv(S), Xtest[i, :].T))\n\n    pred_label = [np.argmax([h(g, i) for g in np.arange(G)])\n                  for i in np.arange(len(Xtest))]\n\n    pred_label = np.asarray(pred_label)\n    return np.mean(pred_label.flatten() != ytest)\n\n# Function to create data list with missing values\ndef make_nan_list(X, y, G, n, p):\n    # Labels should range from 0 to G-1\n    data = []\n    for g in np.arange(G):\n        data.append(X[y == g, :])\n        for k in np.arange(len(p) - 1):\n            data[g][n[g, k + 1]:n[g, k], p[k]:] = np.nan\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:27:41.923509Z","iopub.execute_input":"2024-10-06T13:27:41.924155Z","iopub.status.idle":"2024-10-06T13:27:41.935978Z","shell.execute_reply.started":"2024-10-06T13:27:41.924088Z","shell.execute_reply":"2024-10-06T13:27:41.934833Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def missing_rate(Xtrain, ytrain, n, p, G):\n    Xtr_nan_list = make_nan_list(Xtrain, ytrain, G, n, p)\n    # Generate missing data and a new ytrain since the order might change\n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n\n    for g in np.arange(1, G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # Calculate the percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n    return per_missing","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:27:41.939344Z","iopub.execute_input":"2024-10-06T13:27:41.939988Z","iopub.status.idle":"2024-10-06T13:27:41.952026Z","shell.execute_reply.started":"2024-10-06T13:27:41.939955Z","shell.execute_reply":"2024-10-06T13:27:41.950571Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def compute_err_MICE(Xtrain, ytrain, Xtest, ytest, n, p, G):    \n    Xtr_nan_list = make_nan_list(Xtrain,ytrain,G, n, p)\n    # make NA data\n    # since making function changes the order of observation\n    # we need to generate new ytr from Xtr_nan    \n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n    for g in np.arange(1,G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n\n    scaler = MinMaxScaler()\n    scaler.fit(Xtr_nan)\n    Xtr_nan = scaler.transform(Xtr_nan)\n    Xtest = scaler.transform(Xtest)\n    Xtr_nan_list2 = []\n    for g in range(G):\n      Xtr_nan_list2.append(scaler.transform(Xtr_nan_list[g]))\n\n    \n    #impute,classify and get the error rates for imputation approaches    \n    start = time.time()\n    Xtr_mice = IterativeImputer(max_iter=10).fit(Xtr_nan).transform(Xtr_nan)\n    clf_mice = skLDA().fit(Xtr_mice, ytr)\n    mice_err = np.mean(clf_mice.predict(Xtest).flatten() != ytest)\n    mice_time = time.time()-start\n\n    return mice_err, mice_time","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:27:41.954722Z","iopub.execute_input":"2024-10-06T13:27:41.955158Z","iopub.status.idle":"2024-10-06T13:27:41.966350Z","shell.execute_reply.started":"2024-10-06T13:27:41.955099Z","shell.execute_reply":"2024-10-06T13:27:41.965398Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset instead of MNIST\ndata = pd.read_csv('/kaggle/input/large-diab/large_diab.csv')\n\n# Split into train and test sets if not already done\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Extract features and target\nXtrain = train_data.drop('HeartDiseaseorAttack', axis=1)  # Assuming 'diabetes_status' is the target\nytrain = train_data['HeartDiseaseorAttack']\nXtest = test_data.drop('HeartDiseaseorAttack', axis=1)\nytest = test_data['HeartDiseaseorAttack']","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:27:41.967487Z","iopub.execute_input":"2024-10-06T13:27:41.967765Z","iopub.status.idle":"2024-10-06T13:27:42.639134Z","shell.execute_reply.started":"2024-10-06T13:27:41.967735Z","shell.execute_reply":"2024-10-06T13:27:42.637901Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"data.info","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:27:42.640475Z","iopub.execute_input":"2024-10-06T13:27:42.640819Z","iopub.status.idle":"2024-10-06T13:27:42.680580Z","shell.execute_reply.started":"2024-10-06T13:27:42.640783Z","shell.execute_reply":"2024-10-06T13:27:42.679611Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of         HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n0                        0.0     1.0       1.0        1.0  40.0     1.0   \n1                        0.0     0.0       0.0        0.0  25.0     1.0   \n2                        0.0     1.0       1.0        1.0  28.0     0.0   \n3                        0.0     1.0       0.0        1.0  27.0     0.0   \n4                        0.0     1.0       1.0        1.0  24.0     0.0   \n...                      ...     ...       ...        ...   ...     ...   \n253675                   0.0     1.0       1.0        1.0  45.0     0.0   \n253676                   0.0     1.0       1.0        1.0  18.0     0.0   \n253677                   0.0     0.0       0.0        1.0  28.0     0.0   \n253678                   0.0     1.0       0.0        1.0  23.0     0.0   \n253679                   1.0     1.0       1.0        1.0  25.0     0.0   \n\n        Stroke  Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  \\\n0          0.0       0.0           0.0     0.0  ...            1.0   \n1          0.0       0.0           1.0     0.0  ...            0.0   \n2          0.0       0.0           0.0     1.0  ...            1.0   \n3          0.0       0.0           1.0     1.0  ...            1.0   \n4          0.0       0.0           1.0     1.0  ...            1.0   \n...        ...       ...           ...     ...  ...            ...   \n253675     0.0       0.0           0.0     1.0  ...            1.0   \n253676     0.0       2.0           0.0     0.0  ...            1.0   \n253677     0.0       0.0           1.0     1.0  ...            1.0   \n253678     0.0       0.0           0.0     1.0  ...            1.0   \n253679     0.0       2.0           1.0     1.0  ...            1.0   \n\n        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n...             ...      ...       ...       ...       ...  ...   ...   \n253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n\n        Education  Income  \n0             4.0     3.0  \n1             6.0     1.0  \n2             4.0     8.0  \n3             3.0     6.0  \n4             5.0     4.0  \n...           ...     ...  \n253675        6.0     7.0  \n253676        2.0     4.0  \n253677        5.0     2.0  \n253678        5.0     1.0  \n253679        6.0     2.0  \n\n[253680 rows x 22 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the dataset to NumPy arrays\nXtrain_np, ytrain_np = [], []\nfor index, row in train_data.iterrows():\n    Xtrain_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytrain_np.append(row['HeartDiseaseorAttack'])\n\nXtrain, ytrain = np.asarray(Xtrain_np), np.asarray(ytrain_np)\n\n# Set random seed and shuffle the data\nnp.random.seed(1)\nidx = np.arange(len(ytrain))\nnp.random.shuffle(idx)\nXtrain, ytrain = Xtrain[idx, :], ytrain[idx]\n\nXtrain.shape, ytrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:27:42.681862Z","iopub.execute_input":"2024-10-06T13:27:42.682249Z","iopub.status.idle":"2024-10-06T13:28:41.970965Z","shell.execute_reply.started":"2024-10-06T13:27:42.682215Z","shell.execute_reply":"2024-10-06T13:28:41.970199Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (202944,))"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the test set to NumPy arrays\nXtest_np, ytest_np = [], []\nfor index, row in test_data.iterrows():\n    Xtest_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytest_np.append(row['HeartDiseaseorAttack'])\n\nXtest, ytest = np.asarray(Xtest_np), np.asarray(ytest_np)\n\nXtest = Xtest.astype(float)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:28:41.972387Z","iopub.execute_input":"2024-10-06T13:28:41.972765Z","iopub.status.idle":"2024-10-06T13:28:56.995749Z","shell.execute_reply.started":"2024-10-06T13:28:41.972728Z","shell.execute_reply":"2024-10-06T13:28:56.994890Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Check if a column is mostly zeros (all or almost all zeroes)\nid = [np.sum(Xtrain[:, i] != 0) > 10 for i in range(Xtrain.shape[1])]\n\n# Number of columns that are mostly zero\nprint(Xtrain.shape[1] - np.sum(id))\n\n# Number of columns with more than 10 non-zero values\nprint(np.sum(id))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:28:56.999948Z","iopub.execute_input":"2024-10-06T13:28:57.000382Z","iopub.status.idle":"2024-10-06T13:28:57.036561Z","shell.execute_reply.started":"2024-10-06T13:28:57.000345Z","shell.execute_reply":"2024-10-06T13:28:57.035640Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"0\n21\n","output_type":"stream"}]},{"cell_type":"code","source":"Xtrain, Xtest = Xtrain[:,id], Xtest[:,id]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:28:57.037806Z","iopub.execute_input":"2024-10-06T13:28:57.038107Z","iopub.status.idle":"2024-10-06T13:28:57.068619Z","shell.execute_reply.started":"2024-10-06T13:28:57.038075Z","shell.execute_reply":"2024-10-06T13:28:57.067577Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"Xtrain.shape, Xtest.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:28:57.069918Z","iopub.execute_input":"2024-10-06T13:28:57.070268Z","iopub.status.idle":"2024-10-06T13:28:57.076173Z","shell.execute_reply.started":"2024-10-06T13:28:57.070234Z","shell.execute_reply":"2024-10-06T13:28:57.075258Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (50736, 21))"},"metadata":{}}]},{"cell_type":"code","source":"# Number of samples per class in training data (assuming classes 0 and 1 for diabetes classification)\nng = np.asarray([sum(ytrain == i) for i in np.unique(ytrain)])\nng","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:28:57.077550Z","iopub.execute_input":"2024-10-06T13:28:57.078205Z","iopub.status.idle":"2024-10-06T13:28:57.181990Z","shell.execute_reply.started":"2024-10-06T13:28:57.078160Z","shell.execute_reply":"2024-10-06T13:28:57.181089Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"array([183819,  19125])"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 20% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([200000, 180000, 160000, 140000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:28:57.184032Z","iopub.execute_input":"2024-10-06T13:28:57.184958Z","iopub.status.idle":"2024-10-06T13:28:57.255280Z","shell.execute_reply.started":"2024-10-06T13:28:57.184908Z","shell.execute_reply":"2024-10-06T13:28:57.254370Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"0.05030029395864306"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MICE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:28:57.256648Z","iopub.execute_input":"2024-10-06T13:28:57.257043Z","iopub.status.idle":"2024-10-06T13:30:03.916549Z","shell.execute_reply.started":"2024-10-06T13:28:57.257000Z","shell.execute_reply":"2024-10-06T13:30:03.915359Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(0.0967754651529486, 66.515620470047)"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 30% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([140000, 120000, 110000, 90000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value_30 = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value_30","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:30:03.918076Z","iopub.execute_input":"2024-10-06T13:30:03.919599Z","iopub.status.idle":"2024-10-06T13:30:04.066312Z","shell.execute_reply.started":"2024-10-06T13:30:03.919547Z","shell.execute_reply":"2024-10-06T13:30:04.065334Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"0.18349162236638586"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MICE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:30:04.067605Z","iopub.execute_input":"2024-10-06T13:30:04.068006Z","iopub.status.idle":"2024-10-06T13:31:09.702530Z","shell.execute_reply.started":"2024-10-06T13:30:04.067963Z","shell.execute_reply":"2024-10-06T13:31:09.701643Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(0.0983719646799117, 65.47981238365173)"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 40% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([120000, 100000, 80000, 60000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value_40 = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value_40","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:31:09.704158Z","iopub.execute_input":"2024-10-06T13:31:09.705723Z","iopub.status.idle":"2024-10-06T13:31:09.846033Z","shell.execute_reply.started":"2024-10-06T13:31:09.705679Z","shell.execute_reply":"2024-10-06T13:31:09.845134Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0.24919119137721313"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MICE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:31:09.847168Z","iopub.execute_input":"2024-10-06T13:31:09.847471Z","iopub.status.idle":"2024-10-06T13:32:14.549067Z","shell.execute_reply.started":"2024-10-06T13:31:09.847439Z","shell.execute_reply":"2024-10-06T13:32:14.547894Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(0.10121018606117944, 64.54105854034424)"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 50% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([100000, 90000, 80000, 70000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value_50 = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value_50","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:32:14.550605Z","iopub.execute_input":"2024-10-06T13:32:14.553062Z","iopub.status.idle":"2024-10-06T13:32:14.690587Z","shell.execute_reply.started":"2024-10-06T13:32:14.552997Z","shell.execute_reply":"2024-10-06T13:32:14.689562Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0.2585768440930456"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_MICE(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:32:14.691664Z","iopub.execute_input":"2024-10-06T13:32:14.691963Z","iopub.status.idle":"2024-10-06T13:33:18.392659Z","shell.execute_reply.started":"2024-10-06T13:32:14.691932Z","shell.execute_reply":"2024-10-06T13:33:18.391848Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(0.10154525386313466, 63.55556797981262)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}