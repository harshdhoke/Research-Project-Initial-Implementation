{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9560346,"sourceType":"datasetVersion","datasetId":5825923}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install impyute\n!pip install fancyimpute\nfrom sklearn import datasets\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom scipy import stats\nimport numpy as np\nimport impyute as impy\nfrom fancyimpute import IterativeSVD, SoftImpute, NuclearNormMinimization\nimport pandas as pd\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-06T13:39:42.581835Z","iopub.execute_input":"2024-10-06T13:39:42.582577Z","iopub.status.idle":"2024-10-06T13:40:06.107776Z","shell.execute_reply.started":"2024-10-06T13:39:42.582536Z","shell.execute_reply":"2024-10-06T13:40:06.106718Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Requirement already satisfied: impyute in /opt/conda/lib/python3.10/site-packages (0.0.8)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from impyute) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from impyute) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->impyute) (3.5.0)\nRequirement already satisfied: fancyimpute in /opt/conda/lib/python3.10/site-packages (0.7.0)\nRequirement already satisfied: knnimpute>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (0.1.0)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.2.2)\nRequirement already satisfied: cvxpy in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.5.3)\nRequirement already satisfied: cvxopt in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.3.2)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (8.3.3)\nRequirement already satisfied: nose in /opt/conda/lib/python3.10/site-packages (from fancyimpute) (1.3.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\nRequirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\nRequirement already satisfied: osqp>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.6.7.post1)\nRequirement already satisfied: ecos>=2 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (2.0.14)\nRequirement already satisfied: clarabel>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (0.9.0)\nRequirement already satisfied: scs>=3.2.4.post1 in /opt/conda/lib/python3.10/site-packages (from cvxpy->fancyimpute) (3.2.7)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (21.3)\nRequirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->fancyimpute) (2.0.1)\nRequirement already satisfied: qdldl in /opt/conda/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (0.1.7.post4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pytest->fancyimpute) (3.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef mle(Xtrain, n, p, G):\n    '''\n    Xtrain: List of input. The ith element of the list contains samples from the ith class.\n    Adjusted for the health-related dataset.\n    '''\n    if p[0] == 1:\n        mus = [np.mean(Xtrain[g][:, 0]) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.var(Xtrain[g][:, 0]) for g in np.arange(G)]\n    else:\n        mus = [np.mean(Xtrain[g][:, 0:p[0]], axis=0) for g in np.arange(G)]\n        S = [(n[g, 0] - 1) * np.cov(Xtrain[g][:, 0:p[0]], rowvar=False) for g in np.arange(G)]\n\n    mus = np.asarray(mus).T\n    S = sum(S) / (sum(n[:, 0]))\n    S = S.reshape((p[0], -1))\n\n    for i in np.arange(1, len(p)):\n        W = [(n[g, i] - 1) * np.cov(Xtrain[g][0:n[g, i], 0:p[i]], rowvar=False) for g in np.arange(G)]\n        W = sum(W)\n\n        P = np.matmul(W[(p[i - 1]):p[i], 0:p[i - 1]], np.linalg.inv(W[0:p[i - 1], 0:p[i - 1]]))\n        Q = (W[p[i - 1]:p[i], p[i - 1]:p[i]] - np.matmul(P, W[0:p[i - 1], p[i - 1]:p[i]])) / sum(n[:, i])\n\n        xmeans = [np.mean(Xtrain[g][0:n[g, i], 0:p[i]], axis=0) for g in np.arange(G)]\n        xmeans = np.asarray(xmeans).T\n\n        mus = np.vstack((mus, xmeans[p[i - 1]:p[i], :] - np.matmul(P, xmeans[0:p[i - 1]] - mus)))\n        S21 = np.matmul(P, S)\n        S = np.vstack((np.hstack((S, S21.T)), np.hstack((S21, Q + np.matmul(P, S21.T)))))\n\n    return [mus, S]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:40:06.109811Z","iopub.execute_input":"2024-10-06T13:40:06.110149Z","iopub.status.idle":"2024-10-06T13:40:06.127038Z","shell.execute_reply.started":"2024-10-06T13:40:06.110103Z","shell.execute_reply":"2024-10-06T13:40:06.126030Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Function to calculate misclassification rate for LDA with missing data\ndef lda_miss(mus, S, Xtest, ytrain, ytest, G):\n    f = lambda g: np.log(np.mean(ytrain == g)) - np.matmul(\n                  np.matmul(mus[:,g].T, np.linalg.inv(S)), mus[:,g]/2)\n    last2 = [f(g) for g in np.arange(G)]\n\n    h = lambda g, i: last2[g] + np.matmul(mus[:, g].T, np.matmul(\n                    np.linalg.inv(S), Xtest[i, :].T))\n\n    pred_label = [np.argmax([h(g, i) for g in np.arange(G)])\n                  for i in np.arange(len(Xtest))]\n\n    pred_label = np.asarray(pred_label)\n    return np.mean(pred_label.flatten() != ytest)\n\n# Function to create data list with missing values\ndef make_nan_list(X, y, G, n, p):\n    # Labels should range from 0 to G-1\n    data = []\n    for g in np.arange(G):\n        data.append(X[y == g, :])\n        for k in np.arange(len(p) - 1):\n            data[g][n[g, k + 1]:n[g, k], p[k]:] = np.nan\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:40:06.128391Z","iopub.execute_input":"2024-10-06T13:40:06.128678Z","iopub.status.idle":"2024-10-06T13:40:06.139553Z","shell.execute_reply.started":"2024-10-06T13:40:06.128647Z","shell.execute_reply":"2024-10-06T13:40:06.138813Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def missing_rate(Xtrain, ytrain, n, p, G):\n    Xtr_nan_list = make_nan_list(Xtrain, ytrain, G, n, p)\n    # Generate missing data and a new ytrain since the order might change\n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n\n    for g in np.arange(1, G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # Calculate the percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n    return per_missing","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:40:06.141534Z","iopub.execute_input":"2024-10-06T13:40:06.141826Z","iopub.status.idle":"2024-10-06T13:40:06.155483Z","shell.execute_reply.started":"2024-10-06T13:40:06.141795Z","shell.execute_reply":"2024-10-06T13:40:06.154523Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def compute_err_Nuclear(Xtrain, ytrain, Xtest, ytest, n, p, G):    \n    Xtr_nan_list = make_nan_list(Xtrain,ytrain,G, n, p)\n    # make NA data\n    # since making function changes the order of observation\n    # we need to generate new ytr from Xtr_nan    \n    Xtr_nan, ytr = Xtr_nan_list[0], np.repeat(0, len(Xtr_nan_list[0]))\n    for g in np.arange(1,G):\n        Xtr_nan = np.vstack((Xtr_nan, Xtr_nan_list[g]))\n        ytr = np.hstack((ytr, np.repeat(g, len(Xtr_nan_list[g]))))\n\n    # percentage of missing values\n    per_missing = np.mean(np.isnan(Xtr_nan))\n\n    scaler = MinMaxScaler()\n    scaler.fit(Xtr_nan)\n    Xtr_nan = scaler.transform(Xtr_nan)\n    Xtest = scaler.transform(Xtest)\n    Xtr_nan_list2 = []\n    for g in range(G):\n      Xtr_nan_list2.append(scaler.transform(Xtr_nan_list[g]))\n    \n    #impute,classify and get the error rates for imputation approaches    \n    start = time.time()\n    Xtr_nuclear = NuclearNormMinimization(max_iters=10).fit_transform(Xtr_nan)\n    clf_nuclear = skLDA().fit(Xtr_nuclear, ytr)\n    nuclear_err = np.mean(clf_nuclear.predict(Xtest).flatten() != ytest)\n    nuclear_time = time.time()-start\n \n    return nuclear_err, nuclear_time","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:40:06.156761Z","iopub.execute_input":"2024-10-06T13:40:06.157056Z","iopub.status.idle":"2024-10-06T13:40:06.169928Z","shell.execute_reply.started":"2024-10-06T13:40:06.157025Z","shell.execute_reply":"2024-10-06T13:40:06.169012Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset instead of MNIST\ndata = pd.read_csv('/kaggle/input/large-diab/large_diab.csv')\n\n# Split into train and test sets if not already done\nfrom sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Extract features and target\nXtrain = train_data.drop('HeartDiseaseorAttack', axis=1)  # Assuming 'diabetes_status' is the target\nytrain = train_data['HeartDiseaseorAttack']\nXtest = test_data.drop('HeartDiseaseorAttack', axis=1)\nytest = test_data['HeartDiseaseorAttack']","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:40:06.171183Z","iopub.execute_input":"2024-10-06T13:40:06.171496Z","iopub.status.idle":"2024-10-06T13:40:06.834994Z","shell.execute_reply.started":"2024-10-06T13:40:06.171464Z","shell.execute_reply":"2024-10-06T13:40:06.834177Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"data.info","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:40:06.836172Z","iopub.execute_input":"2024-10-06T13:40:06.836474Z","iopub.status.idle":"2024-10-06T13:40:06.870572Z","shell.execute_reply.started":"2024-10-06T13:40:06.836443Z","shell.execute_reply":"2024-10-06T13:40:06.869692Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of         HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n0                        0.0     1.0       1.0        1.0  40.0     1.0   \n1                        0.0     0.0       0.0        0.0  25.0     1.0   \n2                        0.0     1.0       1.0        1.0  28.0     0.0   \n3                        0.0     1.0       0.0        1.0  27.0     0.0   \n4                        0.0     1.0       1.0        1.0  24.0     0.0   \n...                      ...     ...       ...        ...   ...     ...   \n253675                   0.0     1.0       1.0        1.0  45.0     0.0   \n253676                   0.0     1.0       1.0        1.0  18.0     0.0   \n253677                   0.0     0.0       0.0        1.0  28.0     0.0   \n253678                   0.0     1.0       0.0        1.0  23.0     0.0   \n253679                   1.0     1.0       1.0        1.0  25.0     0.0   \n\n        Stroke  Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  \\\n0          0.0       0.0           0.0     0.0  ...            1.0   \n1          0.0       0.0           1.0     0.0  ...            0.0   \n2          0.0       0.0           0.0     1.0  ...            1.0   \n3          0.0       0.0           1.0     1.0  ...            1.0   \n4          0.0       0.0           1.0     1.0  ...            1.0   \n...        ...       ...           ...     ...  ...            ...   \n253675     0.0       0.0           0.0     1.0  ...            1.0   \n253676     0.0       2.0           0.0     0.0  ...            1.0   \n253677     0.0       0.0           1.0     1.0  ...            1.0   \n253678     0.0       0.0           0.0     1.0  ...            1.0   \n253679     0.0       2.0           1.0     1.0  ...            1.0   \n\n        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n...             ...      ...       ...       ...       ...  ...   ...   \n253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n\n        Education  Income  \n0             4.0     3.0  \n1             6.0     1.0  \n2             4.0     8.0  \n3             3.0     6.0  \n4             5.0     4.0  \n...           ...     ...  \n253675        6.0     7.0  \n253676        2.0     4.0  \n253677        5.0     2.0  \n253678        5.0     1.0  \n253679        6.0     2.0  \n\n[253680 rows x 22 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the dataset to NumPy arrays\nXtrain_np, ytrain_np = [], []\nfor index, row in train_data.iterrows():\n    Xtrain_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytrain_np.append(row['HeartDiseaseorAttack'])\n\nXtrain, ytrain = np.asarray(Xtrain_np), np.asarray(ytrain_np)\n\n# Set random seed and shuffle the data\nnp.random.seed(1)\nidx = np.arange(len(ytrain))\nnp.random.shuffle(idx)\nXtrain, ytrain = Xtrain[idx, :], ytrain[idx]\n\nXtrain.shape, ytrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:40:06.871652Z","iopub.execute_input":"2024-10-06T13:40:06.871962Z","iopub.status.idle":"2024-10-06T13:41:05.405553Z","shell.execute_reply.started":"2024-10-06T13:40:06.871928Z","shell.execute_reply":"2024-10-06T13:41:05.404582Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (202944,))"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the test set to NumPy arrays\nXtest_np, ytest_np = [], []\nfor index, row in test_data.iterrows():\n    Xtest_np.append(row.drop('HeartDiseaseorAttack').values)  # Use all features except the target\n    ytest_np.append(row['HeartDiseaseorAttack'])\n\nXtest, ytest = np.asarray(Xtest_np), np.asarray(ytest_np)\n\nXtest = Xtest.astype(float)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:41:05.406796Z","iopub.execute_input":"2024-10-06T13:41:05.407140Z","iopub.status.idle":"2024-10-06T13:41:20.591030Z","shell.execute_reply.started":"2024-10-06T13:41:05.407094Z","shell.execute_reply":"2024-10-06T13:41:20.589976Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Check if a column is mostly zeros (all or almost all zeroes)\nid = [np.sum(Xtrain[:, i] != 0) > 10 for i in range(Xtrain.shape[1])]\n\n# Number of columns that are mostly zero\nprint(Xtrain.shape[1] - np.sum(id))\n\n# Number of columns with more than 10 non-zero values\nprint(np.sum(id))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:41:20.594445Z","iopub.execute_input":"2024-10-06T13:41:20.594770Z","iopub.status.idle":"2024-10-06T13:41:20.630935Z","shell.execute_reply.started":"2024-10-06T13:41:20.594737Z","shell.execute_reply":"2024-10-06T13:41:20.629915Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"0\n21\n","output_type":"stream"}]},{"cell_type":"code","source":"Xtrain, Xtest = Xtrain[:,id], Xtest[:,id]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:41:20.632012Z","iopub.execute_input":"2024-10-06T13:41:20.632894Z","iopub.status.idle":"2024-10-06T13:41:20.663862Z","shell.execute_reply.started":"2024-10-06T13:41:20.632858Z","shell.execute_reply":"2024-10-06T13:41:20.663044Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"Xtrain.shape, Xtest.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:41:20.664978Z","iopub.execute_input":"2024-10-06T13:41:20.665286Z","iopub.status.idle":"2024-10-06T13:41:20.671733Z","shell.execute_reply.started":"2024-10-06T13:41:20.665255Z","shell.execute_reply":"2024-10-06T13:41:20.670713Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"((202944, 21), (50736, 21))"},"metadata":{}}]},{"cell_type":"code","source":"# Number of samples per class in training data (assuming classes 0 and 1 for diabetes classification)\nng = np.asarray([sum(ytrain == i) for i in np.unique(ytrain)])\nng","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:41:20.672821Z","iopub.execute_input":"2024-10-06T13:41:20.673229Z","iopub.status.idle":"2024-10-06T13:41:20.779745Z","shell.execute_reply.started":"2024-10-06T13:41:20.673196Z","shell.execute_reply":"2024-10-06T13:41:20.778795Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"array([183819,  19125])"},"metadata":{}}]},{"cell_type":"code","source":"# Update 'n' using the actual class distribution for 20% missingness\nn = np.hstack((ng.reshape((-1, 1)), np.tile([200000, 180000, 160000, 140000], len(np.unique(ytrain))).reshape((len(np.unique(ytrain)), -1))))\n\n# Update 'p' using the actual number of features in your dataset\np = np.array([10, 12, 15, 18, Xtrain.shape[1]])\n\n# Calculate the missing rate with updated parameters\nmissing_rate_value = missing_rate(Xtrain, ytrain, n, p, len(np.unique(ytrain)))\nmissing_rate_value","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:41:20.780819Z","iopub.execute_input":"2024-10-06T13:41:20.781105Z","iopub.status.idle":"2024-10-06T13:41:20.850219Z","shell.execute_reply.started":"2024-10-06T13:41:20.781072Z","shell.execute_reply":"2024-10-06T13:41:20.849298Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"0.05030029395864306"},"metadata":{}}]},{"cell_type":"code","source":"compute_err_Nuclear(Xtrain, ytrain, Xtest, ytest, n, p, len(np.unique(ytrain)))","metadata":{"execution":{"iopub.status.busy":"2024-10-06T13:41:20.851209Z","iopub.execute_input":"2024-10-06T13:41:20.851472Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"===============================================================================\n                                     CVXPY                                     \n                                     v1.5.3                                    \n===============================================================================\n(CVXPY) Oct 06 01:41:21 PM: Your problem has 4261824 variables, 4261824 constraints, and 0 parameters.\n(CVXPY) Oct 06 01:41:21 PM: It is compliant with the following grammars: DCP, DQCP\n(CVXPY) Oct 06 01:41:21 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n(CVXPY) Oct 06 01:41:21 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n(CVXPY) Oct 06 01:41:21 PM: Your problem is compiled with the CPP canonicalization backend.\n-------------------------------------------------------------------------------\n                                  Compilation                                  \n-------------------------------------------------------------------------------\n(CVXPY) Oct 06 01:41:21 PM: Compiling problem (target solver=CVXOPT).\n(CVXPY) Oct 06 01:41:21 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> CVXOPT\n(CVXPY) Oct 06 01:41:21 PM: Applying reduction Dcp2Cone\n(CVXPY) Oct 06 01:41:21 PM: Applying reduction CvxAttr2Constr\n","output_type":"stream"}]}]}